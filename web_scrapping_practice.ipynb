{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn0ml6Cs2434k8Z7aMsN+4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anish3333/ML-Practice/blob/main/web_scrapping_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# web scrapping"
      ],
      "metadata": {
        "id": "6emc0uYVXy4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P3x4gMrRKvk8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
        "url = 'https://www.ambitionbox.com/list-of-companies?page=1'"
      ],
      "metadata": {
        "id": "hl061PJULVAe"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "for i in range(1, 7):\n",
        "  url = f'https://www.ambitionbox.com/list-of-companies?page={i}'\n",
        "  web_page = requests.get(url, headers=headers).text\n",
        "  soup = BeautifulSoup(web_page, 'lxml')\n",
        "  company_divs = soup.find_all('div', class_='companyCardWrapper')\n",
        "\n",
        "  name = []\n",
        "  rating = []\n",
        "  reviews=[]\n",
        "  interviews=[]\n",
        "  jobs=[]\n",
        "\n",
        "  for company in company_divs:\n",
        "    name.append( company.find('h2', class_='companyCardWrapper__companyName').text.strip() )\n",
        "    rating.append(company.find('span', class_='companyCardWrapper__companyRatingValue').text.strip())\n",
        "    reviews.append(company.find_all('span', class_='companyCardWrapper__ActionCount')[0].text.strip())\n",
        "    interviews.append(company.find_all('span', class_='companyCardWrapper__ActionCount')[2].text.strip())\n",
        "    jobs.append(company.find_all('span', class_='companyCardWrapper__ActionCount')[3].text.strip())\n",
        "\n",
        "  d = {'name': name, 'ratings': rating, 'reviews': reviews, 'interviews': interviews, 'jobs': jobs}\n",
        "  temp = pd.DataFrame(d)\n",
        "  df = pd.concat([df, temp], ignore_index=True)"
      ],
      "metadata": {
        "id": "8Wyqp96mNeVP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.to_csv('anish.csv')"
      ],
      "metadata": {
        "id": "BGgUb3tdXcSx"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OcplcryBXwWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}